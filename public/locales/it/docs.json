{
  "title": "Documentazione",
  "subtitle": "Scopri come creare API di intelligenza artificiale strutturate con {{appName}}",
  "seo": {
    "gettingStarted": "Scopri come iniziare con {{appName}}. Crea progetti, configura i provider di LLM e crea il tuo primo endpoint AI strutturato.",
    "concepts": "Comprendi i concetti fondamentali: endpoint, schemi JSON, contesto del sistema e percorsi di organizzazione per creare API AI strutturate.",
    "apiReference": "Riferimento completo dell'API per {{appName}. Endpoint REST, formati delle richieste, strutture delle risposte e esempi di codice.",
    "default": "Documentazione di {{appName}}. Impara a creare API REST affidabili con intelligenza artificiale e convalida tramite JSON Schema."
  },
  "howTo": {
    "name": "Come creare un endpoint LLM strutturato",
    "description": "Guida passo passo per creare il tuo primo endpoint API con IA strutturata con {{appName}}",
    "steps": {
      "createProject": {
        "name": "Crea un progetto",
        "text": "Inizia creando un nuovo progetto nel tuo pannello di controllo per organizzare gli endpoint."
      },
      "addProvider": {
        "name": "Aggiungi un provider di LLM",
        "text": "Configura la tua chiave API per OpenAI, Anthropic, Google Gemini o un server LM personalizzato."
      },
      "defineEndpoint": {
        "name": "Definire un Endpoint",
        "text": "Crea un endpoint con istruzioni, contesto e schema di output JSON."
      },
      "testEndpoint": {
        "name": "Prova il tuo endpoint",
        "text": "Utilizza il tester integrato per verificare che il tuo endpoint restituisca dati strutturati."
      },
      "integrate": {
        "name": "Integra",
        "text": "Chiami il tuo endpoint dall'applicazione utilizzando semplici richieste GET o POST."
      }
    }
  },
  "nav": {
    "gettingStarted": "Iniziare",
    "concepts": "Concetti fondamentali",
    "apiReference": "Riferimento API"
  },
  "gettingStarted": {
    "title": "Iniziare",
    "steps": [
      {
        "title": "Crea un progetto",
        "description": "Inizia creando un nuovo progetto nel tuo pannello di controllo. Assegna un nome e una descrizione facoltativa."
      },
      {
        "title": "Aggiungi un provider",
        "description": "Configura la tua chiave API per OpenAI, Anthropic, Google Gemini o un server LM personalizzato."
      },
      {
        "title": "Definire un Endpoint",
        "description": "Crea un endpoint con lo schema JSON di output, istruzioni e contesto. Collegalo alla tua chiave LLM."
      },
      {
        "title": "Imposta il percorso della tua organizzazione",
        "description": "Configura un percorso personalizzato per l'organizzazione nelle impostazioni, oppure utilizza il percorso predefinito generato automaticamente."
      },
      {
        "title": "Integra",
        "description": "Chiami il tuo endpoint dalla tua applicazione utilizzando semplici richieste GET o POST."
      }
    ]
  },
  "concepts": {
    "title": "Concetti fondamentali",
    "endpoints": {
      "title": "Endpoint",
      "description": "Ogni endpoint è configurato con:",
      "items": [
        {
          "name": "Schema di input",
          "description": "Schema JSON che definisce la struttura prevista dei dati in ingresso (facoltativo)"
        },
        {
          "name": "Schema di output",
          "description": "Schema JSON che definisce la struttura della risposta dell'LLM"
        },
        {
          "name": "Istruzioni",
          "description": "Istruzioni specifiche per indicare all'LLM cosa fare con l'input"
        },
        {
          "name": "Contesto",
          "description": "Prompt di contesto di sistema per guidare il comportamento dell'LLM"
        },
        {
          "name": "Metodo HTTP",
          "description": "GET (parametri di query) o POST (corpo JSON) per i dati in input"
        }
      ]
    },
    "inputSchema": {
      "title": "Schema di input",
      "description": "Definisci la struttura prevista dei dati in ingresso utilizzando JSON Schema. Quando i chiamanti inviano dati al tuo endpoint, {{appName}} verifica che siano conformi allo schema di input prima del processamento. Ciò garantisce che il tuo LLM riceva dati ben formati e fornisca messaggi di errore chiari per le richieste non valide."
    },
    "outputSchema": {
      "title": "Schema di output",
      "description": "Definisci la struttura delle risposte dell'LLM utilizzando lo schema JSON. {{appName}} istruisce l'LLM a restituire dati che corrispondono allo schema e verifica la risposta, ripetendo automaticamente se la risposta non è conforme."
    },
    "context": {
      "title": "Contesto del sistema",
      "description": "Fornisci prompt di sistema per guidare il comportamento dell'LLM. Questo contesto viene incluso in ogni richiesta al tuo endpoint."
    },
    "organizationPath": {
      "title": "Percorso dell'organizzazione",
      "description": "Il percorso della tua organizzazione viene utilizzato negli URL dell'API. Inizialmente corrisponde ai primi 8 caratteri del tuo ID utente, ma puoi personalizzarlo nelle impostazioni."
    }
  },
  "apiReference": {
    "title": "Riferimento API",
    "description": "Accedi ai tuoi endpoint tramite REST API. Tutti gli endpoint AI sono pubblici e non richiedono autenticazione.",
    "endpoints": {
      "main": {
        "title": "Esegui Endpoint",
        "get": "GET /api/v1/ai/:orgPath/:projectName/:endpointName",
        "post": "POST /api/v1/ia/:orgPath/:projectName/:endpointName",
        "description": "Esegue l'endpoint e restituisce la risposta dell'LLM con le metriche di utilizzo."
      },
      "prompt": {
        "title": "Ottenere solo il prompt",
        "get": "GET /api/v1/ia/:orgPath/:projectName/:endpointName/prompt",
        "post": "POST /api/v1/ia/:orgPath/:projectName/:endpointName/prompt",
        "description": "Restituisce il prompt generato senza richiamare il modello linguistico. Utile per il debug."
      }
    },
    "response": {
      "title": "Formato risposta",
      "description": "Le risposte corrette includono l'output dell'LLM e le statistiche di utilizzo:",
      "fields": [
        {
          "name": "output",
          "description": "La risposta strutturata fornita dal modello linguistico che corrisponde al tuo schema di output"
        },
        {
          "name": "usage.tokens_input",
          "description": "Numero di token di input utilizzati"
        },
        {
          "name": "usage.tokens_output",
          "description": "Numero di token di output generati"
        },
        {
          "name": "latenza_ms",
          "description": "Latenza della richiesta in millisecondi"
        },
        {
          "name": "costo stimato in centesimi di dollaro",
          "description": "Costo stimato in centesimi"
        }
      ]
    },
    "example": {
      "requestTitle": "Esempio di richiesta",
      "responseTitle": "Risposta di esempio"
    }
  }
}
