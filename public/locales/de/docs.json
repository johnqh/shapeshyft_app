{
  "title": "Dokumentation",
  "subtitle": "Erfahren Sie, wie Sie mit {{appName}} strukturierte AI-APIs erstellen",
  "seo": {
    "gettingStarted": "Erfahren Sie, wie Sie mit {{appName}} beginnen. Erstellen Sie Projekte, konfigurieren Sie LLM-Anbieter und erstellen Sie Ihre erste strukturierte AI-Endpunkt.",
    "concepts": "Verstehen Sie die Grundkonzepte: Endpunkte, JSON-Schemas, Systemkontext und Organisationspfade zur Erstellung strukturierter AI-APIs.",
    "apiReference": "Vollständige API-Referenz für {{appName}. REST-Endpunkte, Anforderungsformate, Antwortstrukturen und Codebeispiele.",
    "default": "{{appName}} Dokumentation. Erfahren Sie, wie Sie zuverlässige, KI-gestützte REST-APIs mit JSON-Schema-Validierung erstellen."
  },
  "howTo": {
    "name": "Wie man einen strukturierten LLM-Endpunkt erstellt",
    "description": "Schritt-für-Schritt-Anleitung zum Erstellen Ihres ersten strukturierten AI-API-Endpunkts mit {{appName}}",
    "steps": {
      "createProject": {
        "name": "Projekt erstellen",
        "text": "Erstellen Sie zunächst ein neues Projekt in Ihrem Dashboard, um Ihre Endpunkte zu organisieren."
      },
      "addProvider": {
        "name": "LLM-Anbieter hinzufügen",
        "text": "Konfigurieren Sie Ihren API-Schlüssel für OpenAI, Anthropic, Google Gemini oder einen benutzerdefinierten LM-Server."
      },
      "defineEndpoint": {
        "name": "Definieren Sie einen Endpunkt",
        "text": "Erstellen Sie einen Endpunkt mit Anweisungen, Kontext und JSON-Ausgabeschema."
      },
      "testEndpoint": {
        "name": "Testen Sie Ihren Endpunkt",
        "text": "Verwenden Sie den integrierten Tester, um zu überprüfen, ob Ihre Endpunkt strukturierte Daten zurückgibt."
      },
      "integrate": {
        "name": "Integrieren",
        "text": "Rufen Sie Ihre Endpunkt aus Ihrer Anwendung mit einfachen GET- oder POST-Anfragen auf."
      }
    }
  },
  "nav": {
    "gettingStarted": "Erste Schritte",
    "concepts": "Grundlegende Konzepte",
    "apiReference": "API-Referenz"
  },
  "gettingStarted": {
    "title": "Erste Schritte",
    "steps": [
      {
        "title": "Projekt erstellen",
        "description": "Legen Sie zunächst ein neues Projekt in Ihrem Dashboard an. Geben Sie ihm einen Namen und eine optionale Beschreibung."
      },
      {
        "title": "Anbieter hinzufügen",
        "description": "Konfigurieren Sie Ihren API-Schlüssel für OpenAI, Anthropic, Google Gemini oder einen benutzerdefinierten LM-Server."
      },
      {
        "title": "Definieren Sie einen Endpunkt",
        "description": "Erstellen Sie einen Endpunkt mit Ausgabedaten-JSON-Schema, Anweisungen und Kontext. Stellen Sie eine Verbindung zu Ihrem LLM-Schlüssel her."
      },
      {
        "title": "Legen Sie Ihren Organisationspfad fest",
        "description": "Konfigurieren Sie einen benutzerdefinierten Organisationspfad in den Einstellungen oder verwenden Sie Ihren automatisch generierten Standardpfad."
      },
      {
        "title": "Integrieren",
        "description": "Rufen Sie Ihre Endpunkt aus Ihrer Anwendung mit einfachen GET- oder POST-Anfragen auf."
      }
    ]
  },
  "concepts": {
    "title": "Grundlegende Konzepte",
    "endpoints": {
      "title": "Endpunkte",
      "description": "Jeder Endpunkt ist konfiguriert mit:",
      "items": [
        {
          "name": "Eingabeschema",
          "description": "JSON-Schema zur Definition der erwarteten Struktur der Eingabedaten (optional)"
        },
        {
          "name": "Ausgabeschema",
          "description": "JSON-Schema zur Definition der Struktur der LLM-Antwort"
        },
        {
          "name": "Anweisungen",
          "description": "Spezifische Anweisungen dafür, was die LLM mit der Eingabe tun soll"
        },
        {
          "name": "Kontext",
          "description": "Systemkontext/Aufforderung, um das Verhalten des LLMs zu leiten"
        },
        {
          "name": "HTTP-Methode",
          "description": "GET (Abfrageparameter) oder POST (JSON-Körper) für Eingabedaten"
        }
      ]
    },
    "inputSchema": {
      "title": "Eingabeschema",
      "description": "Definieren Sie die erwartete Struktur der Eingabedaten mithilfe von JSON Schema. Bevor Ihre Endpoint verarbeitet, überprüft {{appName}} die Daten anhand Ihrer Eingabeschema. Dadurch wird sichergestellt, dass Ihr LLM gutgeformte Daten erhält, und es werden klare Fehlermeldungen für ungültige Anfragen bereitgestellt."
    },
    "outputSchema": {
      "title": "Ausgabeschema",
      "description": "Definieren Sie die Struktur von LLM-Ausgaben mithilfe von JSON-Schema. {{appName}} weist die LLM an, Daten im Einklang mit Ihrem Schema zurückzugeben und die Antwort zu validieren, wobei automatisch erneut versucht wird, falls die Ausgabe nicht konform ist."
    },
    "context": {
      "title": "Systemkontext",
      "description": "Geben Sie Systemprompts an, um das Verhalten des LLM zu leiten. Dieser Kontext wird jeder Anfrage an Ihren Endpunkt beigefügt."
    },
    "organizationPath": {
      "title": "Organisationspfad",
      "description": "Der Organisationspfad wird in API-URLs verwendet. Standardmäßig besteht er aus den ersten 8 Zeichen Ihrer Benutzer-ID, kann aber in den Einstellungen angepasst werden."
    }
  },
  "apiReference": {
    "title": "API-Referenz",
    "description": "Greifen Sie Ihre Endpunkte über die REST-API zu. Alle AI-Endpunkte sind öffentlich und erfordern keine Authentifizierung.",
    "endpoints": {
      "main": {
        "title": "Endpoint ausführen",
        "get": "GET /api/v1/ai/:orgPath/:projectName/:endpointName",
        "post": "POST /api/v1/ai/:orgPath/:projectName/:endpointName",
        "description": "Führt den Endpunkt aus und gibt die LLM-Antwort mit Nutzungsmetriken zurück."
      },
      "prompt": {
        "title": "Nur Prompt erhalten",
        "get": "GET /api/v1/ai/:orgPath/:projectName/:endpointName/prompt",
        "post": "POST /api/v1/ai/:orgPath/:projectName/:endpointName/prompt",
        "description": "Gibt den generierten Prompt zurück, ohne die LLM aufzurufen. Nützlich für die Fehlerbehebung."
      }
    },
    "response": {
      "title": "Antwortformat",
      "description": "Erfolgreiche Antworten enthalten die LLM-Ausgabe und Nutzungsstatistiken:",
      "fields": [
        {
          "name": "Ausgabe",
          "description": "Die strukturierte Antwort vom LLM, die deinem Ausgabeschema entspricht"
        },
        {
          "name": "usage.tokens_input",
          "description": "Anzahl verwendeter Eingabetoken"
        },
        {
          "name": "usage.tokens_output",
          "description": "Anzahl generierter Ausgabetokens"
        },
        {
          "name": "usage.latency_ms",
          "description": "Anforderungs-Latenz in Millisekunden"
        },
        {
          "name": "Verwendung.geschätzter_Kosten_Cent",
          "description": "Geschätzte Kosten in Cent"
        }
      ]
    },
    "example": {
      "requestTitle": "Beispiel-Anfrage",
      "responseTitle": "Beispielantwort"
    }
  }
}
