{
  "title": "Documentation",
  "subtitle": "Apprenez à créer des API d'IA structurées avec {{appName}}",
  "seo": {
    "gettingStarted": "Découvrez comment commencer avec {{appName}}. Créez des projets, configurez les fournisseurs d'LLM et créez votre premier point d'entrée AI structuré.",
    "concepts": "Comprendre les concepts fondamentaux : points d'entrée, schémas JSON, contexte système et chemins d'organisation pour créer des API IA structurées.",
    "apiReference": "Référence complète de l'API pour {{appName}. Points d'extrémité REST, formats de requête, structures de réponse et exemples de code.",
    "default": "Documentation de {{appName}}. Découvrez comment créer des API REST fiables alimentées par l'IA avec une validation JSON Schema."
  },
  "howTo": {
    "name": "Comment créer une fin d'endpoint structurée pour un modèle de langage",
    "description": "Guide pas à pas pour créer votre premier point d'entrée d'API IA structurée avec {{appName}}",
    "steps": {
      "createProject": {
        "name": "Créer un projet",
        "text": "Commencez par créer un nouveau projet dans votre tableau de bord pour organiser vos points de terminaison."
      },
      "addProvider": {
        "name": "Ajouter un fournisseur d'LLM",
        "text": "Configurez votre clé API pour OpenAI, Anthropic, Google Gemini ou un serveur de modèle linguistique personnalisé."
      },
      "defineEndpoint": {
        "name": "Définir une URL de point d'entrée",
        "text": "Créez un point de terminaison avec des instructions, un contexte et un schéma de sortie JSON."
      },
      "testEndpoint": {
        "name": "Testez votre point de terminaison",
        "text": "Utilisez le testeur intégré pour vérifier que votre point de terminaison renvoie des données structurées."
      },
      "integrate": {
        "name": "Intégrer",
        "text": "Appelez votre point de terminaison depuis votre application à l'aide de requêtes GET ou POST simples."
      }
    }
  },
  "nav": {
    "gettingStarted": "Mise en route",
    "concepts": "Concepts fondamentaux",
    "apiReference": "Référence de l'API"
  },
  "gettingStarted": {
    "title": "Mise en route",
    "steps": [
      {
        "title": "Créer un projet",
        "description": "Commencez par créer un nouveau projet dans votre tableau de bord. Donnez-lui un nom et une description facultative."
      },
      {
        "title": "Ajouter un fournisseur",
        "description": "Configurez votre clé API pour OpenAI, Anthropic, Google Gemini ou un serveur de modèle linguistique personnalisé."
      },
      {
        "title": "Définir une URL de point d'entrée",
        "description": "Créez un point de terminaison avec un schéma de sortie JSON, des instructions et un contexte. Liez-le à votre clé LLM."
      },
      {
        "title": "Définissez le chemin de votre organisation",
        "description": "Configurez un chemin d'organisation personnalisé dans les paramètres, ou utilisez le chemin par défaut généré automatiquement."
      },
      {
        "title": "Intégrer",
        "description": "Appelez votre point de terminaison depuis votre application à l'aide de requêtes GET ou POST simples."
      }
    ]
  },
  "concepts": {
    "title": "Concepts fondamentaux",
    "endpoints": {
      "title": "Points d'accès",
      "description": "Chaque point de terminaison est configuré avec :",
      "items": [
        {
          "name": "Schéma d'entrée",
          "description": "Schéma JSON définissant la structure attendue des données d'entrée (facultatif)"
        },
        {
          "name": "Schéma de sortie",
          "description": "Schéma JSON définissant la structure de la réponse de l'LLM"
        },
        {
          "name": "Instructions",
          "description": "Instructions spécifiques pour indiquer au modèle linguistique (LLM) ce qu'il doit faire avec l'entrée"
        },
        {
          "name": "Contexte",
          "description": "Contexte système/prompt pour guider le comportement du LLM"
        },
        {
          "name": "Méthode HTTP",
          "description": "GET (paramètres de requête) ou POST (corps JSON) pour les données d'entrée"
        }
      ]
    },
    "inputSchema": {
      "title": "Schéma d'entrée",
      "description": "Définissez la structure attendue des données d'entrée à l'aide d'un schéma JSON. Avant de traiter les données, {{appName}} les valide selon votre schéma d'entrée. Cela garantit que votre modèle de langage reçoit des données correctement formées et fournit des messages d'erreur clairs pour les requêtes non valides."
    },
    "outputSchema": {
      "title": "Schéma de sortie",
      "description": "Définissez la structure des sorties du LLM à l'aide d'un schéma JSON. {{appName}} indique au LLM de retourner des données correspondant à votre schéma et de valider la réponse, en réessayant automatiquement si la sortie ne correspond pas."
    },
    "context": {
      "title": "Context du système",
      "description": "Fournissez des invites système pour guider le comportement du LLM. Ce contexte est inclus avec chaque requête adressée à votre point d'entrée."
    },
    "organizationPath": {
      "title": "Chemin de l'organisation",
      "description": "Votre chemin d'organisation est utilisé dans les URL de l'API. Par défaut, il correspond aux 8 premiers caractères de votre identifiant utilisateur, mais vous pouvez le personnaliser dans les paramètres."
    }
  },
  "apiReference": {
    "title": "Référence de l'API",
    "description": "Accédez à vos points de terminaison via l'API REST. Tous les points de terminaison IA sont publics et ne nécessitent pas d'authentification.",
    "endpoints": {
      "main": {
        "title": "Exécuter le point de terminaison",
        "get": "GET /api/v1/ia/:orgPath/:projectName/:endpointName",
        "post": "POST /api/v1/ia/:orgPath/:projectName/:endpointName",
        "description": "Exécute le point de terminaison et renvoie la réponse du LLM avec les métriques d'utilisation."
      },
      "prompt": {
        "title": "Obtenir uniquement l'invite",
        "get": "GET /api/v1/ia/:orgPath/:projectName/:endpointName/prompt",
        "post": "POST /api/v1/ia/:orgPath/:projectName/:endpointName/prompt",
        "description": "Retourne la requête générée sans appeler le modèle de langage. Utile pour le débogage."
      }
    },
    "response": {
      "title": "Format de réponse",
      "description": "Les réponses réussies incluent la sortie du LLM et les statistiques d'utilisation :",
      "fields": [
        {
          "name": "sortie",
          "description": "La réponse structurée fournie par le modèle de langage correspondant à votre schéma de sortie"
        },
        {
          "name": "usage.tokens_input",
          "description": "Nombre de jetons d'entrée utilisés"
        },
        {
          "name": "usage.tokens_output",
          "description": "Nombre de jetons de sortie générés"
        },
        {
          "name": "latence_ms",
          "description": "Latence de requête en millisecondes"
        },
        {
          "name": "utilisation.coût_estimé_cents",
          "description": "Coût estimé en centimes"
        }
      ]
    },
    "example": {
      "requestTitle": "Example de demande",
      "responseTitle": "Réponse d'exemple"
    }
  }
}